{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis after we built the data collection. now is Vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import codecs\n",
    "import re\n",
    "import os\n",
    "import matplotlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # a conventional alias\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we need to see about the stopword list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'\\u8981', u'\\u4e00', u'\\u7684', u'\\u5c06', u'\\u6709', u'\\u628a', u'\\u4e0d', u'\\u4e8c', u'\\u4e0e', u'\\u6211', u'\\u4e09', u'\\u5f97', u'\\u90a3', u'\\u5728', u'\\u4e86', u'\\u542c', u'\\u662f', u'\\u5230', u'\\u5bb6', u'\\u4eba', u'\\u89c1', u'\\u4e0a', u'\\u65e0', u'\\u53c8', u'\\u4ed6', u'\\u8fd9', u'\\u4e5f', u'\\u4f60', u'\\u4e3a', u'\\u6765', u'\\u53ea', u'\\u8bf4', u'\\u597d'])\n"
     ]
    }
   ],
   "source": [
    "print stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二黄原板.txt      二黄摇板.txt      西皮快板.txt      西皮摇板.txt\r\n",
      "二黄慢板.txt      西皮原板.txt      西皮慢板.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls sqbs7_all_docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqbs7_all_docs/二黄原板.txt\n",
      "sqbs7_all_docs/二黄慢板.txt\n",
      "sqbs7_all_docs/二黄摇板.txt\n",
      "sqbs7_all_docs/西皮原板.txt\n",
      "sqbs7_all_docs/西皮快板.txt\n",
      "sqbs7_all_docs/西皮慢板.txt\n",
      "sqbs7_all_docs/西皮摇板.txt\n"
     ]
    }
   ],
   "source": [
    "for i in filenames:print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#notice that we need to tweak the settings for countVectorizer for the need of unicode. here is some documentations:\n",
    "token_pattern : string\n",
    "Regular expression denoting what constitutes a “token”, only used if tokenize == ‘word’. \n",
    "The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).\n",
    "\n",
    "\n",
    "tokenizer : callable or None (default)\n",
    "Override the string tokenization step while preserving the preprocessing and n-grams generation steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_ori='我 一 不 你 把 了 是 来 在 他 的 有 将 见 人 与 得 要 到 听 那 又 为 上 这 三 只 好 二 说 无 家 也'\n",
    "frwords=codecs.decode(stop_ori,'utf-8')\n",
    "stoplist=set(frwords.split())\n",
    "stoplist_ori=set(stop_ori.split())#not useful now\n",
    "\n",
    "corpus_path = 'sqbs7_all_docs'\n",
    "filenames=[os.path.join(corpus_path, fn) for fn in sorted(os.listdir(corpus_path))]\n",
    "if 'sqbs7_all_docs/.DS_Store' in filenames:\n",
    "    filenames.remove('sqbs7_all_docs/.DS_Store')\n",
    "\n",
    "\n",
    "\n",
    "pat=re.compile(r'(?u)\\b\\w+\\b',re.UNICODE )\n",
    "vectorizer = CountVectorizer(input='filename',stop_words=stoplist,token_pattern=pat) \n",
    "dtm = vectorizer.fit_transform(filenames)  # a sparse matrix \n",
    "vocab_list = vectorizer.get_feature_names()\n",
    "type(dtm)                                         \n",
    "dtm = dtm.toarray()  # convert to a regular array \n",
    "#note that vocab_list is a python list, vocab is a numpy array\n",
    "vocab = np.array(vocab_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#what is the top words? in each document\n",
    "def get_word_dist(i):\n",
    "    \"\"\"input is the index of the document, such as i=1 is the first document\"\"\"\n",
    "    fdist=[]\n",
    "    for word in vocab_list:\n",
    "        #print word\n",
    "        freq=dtm[i, vocab == word]\n",
    "        fdist.append((word,freq[0]))\n",
    "\n",
    "    rank=sorted(fdist, key=lambda x: x[1])[::-1]\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqbs7_all_docs/二黄原板.txt\n",
      "想 64\n",
      "叫 64\n",
      "里 58\n",
      "去 50\n",
      "此 45\n",
      "娘 43\n",
      "臣 42\n",
      "小 41\n",
      "都 40\n",
      "本 40\n",
      "孤 38\n",
      "但愿 38\n",
      "老 37\n",
      "言 36\n",
      "儿 36\n",
      "下 35\n",
      "能 34\n",
      "声 34\n",
      "个 34\n",
      "难 33\n",
      "sqbs7_all_docs/二黄慢板.txt\n",
      "谁 16\n",
      "臣 16\n",
      "恨 16\n",
      "坐 16\n",
      "起 15\n",
      "老 15\n",
      "想 14\n",
      "个 13\n",
      "里 12\n",
      "下 12\n",
      "难 11\n",
      "江山 11\n",
      "曾 11\n",
      "命 11\n",
      "可怜 11\n",
      "去 11\n",
      "中 11\n",
      "知 10\n",
      "看 10\n",
      "此 10\n",
      "sqbs7_all_docs/二黄摇板.txt\n",
      "去 70\n",
      "叫 63\n",
      "命 54\n",
      "里 46\n",
      "两 46\n",
      "心 43\n",
      "小 43\n",
      "老 42\n",
      "泪 42\n",
      "儿 41\n",
      "定 40\n",
      "进 39\n",
      "问 37\n",
      "打 36\n",
      "但愿 36\n",
      "下 36\n",
      "此 35\n",
      "分明 34\n",
      "声 33\n",
      "再 32\n",
      "sqbs7_all_docs/西皮原板.txt\n",
      "叫 99\n",
      "里 82\n",
      "去 82\n",
      "看 56\n",
      "声 55\n",
      "再 51\n",
      "个 49\n",
      "两 47\n",
      "问 46\n",
      "恨 46\n",
      "言 45\n",
      "分明 44\n",
      "中 44\n",
      "心 43\n",
      "小 43\n",
      "此 42\n",
      "下 42\n",
      "众 41\n",
      "日 40\n",
      "似 39\n",
      "sqbs7_all_docs/西皮快板.txt\n",
      "个 91\n",
      "去 84\n",
      "叫 78\n",
      "孤 72\n",
      "王 68\n",
      "言 67\n",
      "就 62\n",
      "本 56\n",
      "下 56\n",
      "若 53\n",
      "两 51\n",
      "什么 50\n",
      "老 49\n",
      "难 48\n",
      "小 48\n",
      "再 48\n",
      "斩 47\n",
      "心 47\n",
      "话 46\n",
      "讲 44\n",
      "sqbs7_all_docs/西皮慢板.txt\n",
      "里 40\n",
      "叫 32\n",
      "去 32\n",
      "奴 31\n",
      "吾 23\n",
      "个 22\n",
      "用 21\n",
      "本 20\n",
      "事 20\n",
      "老 19\n",
      "才 19\n",
      "想 19\n",
      "都 18\n",
      "言 18\n",
      "自 18\n",
      "坐 18\n",
      "命 18\n",
      "两 18\n",
      "下 18\n",
      "细 17\n",
      "sqbs7_all_docs/西皮摇板.txt\n",
      "去 258\n",
      "叫 245\n",
      "此 158\n",
      "且 144\n",
      "看 140\n",
      "心 137\n",
      "命 134\n",
      "难 133\n",
      "里 126\n",
      "言 126\n",
      "两 126\n",
      "再 125\n",
      "中 125\n",
      "进 118\n",
      "问 117\n",
      "个 116\n",
      "下 112\n",
      "今日 111\n",
      "事 111\n",
      "孤 109\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print filenames[i]\n",
    "    rank=get_word_dist(i)\n",
    "    for words in rank[:20]:\n",
    "        print words[0],words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#after observing these top words from individual files, we need to add some entries to the stop list. Let's first see\n",
    "#what if we take all words and see the top words\n",
    "\n",
    "all_dtm=np.sum(dtm,axis=0)\n",
    "def get_word_dist_all():\n",
    "    \"\"\"input is the index of the document, such as i=1 is the first document\"\"\"\n",
    "    fdist=[]\n",
    "    for word in vocab_list:\n",
    "        #print word\n",
    "        freq=all_dtm[vocab == word]\n",
    "        fdist.append((word,freq[0]))\n",
    "\n",
    "    rank=sorted(fdist, key=lambda x: x[1])[::-1]\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "叫 587 去 587 里 400 个 351 此 347 言 326 两 324 看 317 心 311 下 311 孤 308 命 308 小 301 再 293 中 292 难 288 声 287 老 284 想 275 问 263 且 261 本 260 事 256 能 245 话 240 进 239 分明 238 王 229 儿 225 大 221 臣 219 但愿 219 谁 217 今日 214 怎 213 出 213 恨 212 就 212 和 211 前 211 她 205 贼 204 似 204 定 201 才 200 哪 199 泪 195 日 191 太 191 朝 190\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rank=get_word_dist_all()\n",
    "for words in rank[:50]:\n",
    "    print words[0],words[1],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#it seems like these are all pretty meaningless. The thing is that either this would mean we want more in the stop list,\n",
    "#or this says something about the quality of segmentation. but what if we used all one character words tokenization? \n",
    "#worse? hard to imagine.\n",
    "\n",
    "#since there are other devices like tf-idf weighting, we're going to leave words in for now. top words in frequency \n",
    "#doesn't mean topic words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity between 7 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.28,  0.2 ,  0.19,  0.22,  0.24,  0.19],\n",
       "       [ 0.28,  0.  ,  0.36,  0.32,  0.35,  0.33,  0.35],\n",
       "       [ 0.2 ,  0.36,  0.  ,  0.21,  0.22,  0.29,  0.13],\n",
       "       [ 0.19,  0.32,  0.21, -0.  ,  0.18,  0.2 ,  0.13],\n",
       "       [ 0.22,  0.35,  0.22,  0.18,  0.  ,  0.26,  0.14],\n",
       "       [ 0.24,  0.33,  0.29,  0.2 ,  0.26,  0.  ,  0.24],\n",
       "       [ 0.19,  0.35,  0.13,  0.13,  0.14,  0.24, -0.  ]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [24]: from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "In [25]: dist = 1 - cosine_similarity(dtm)\n",
    "\n",
    "In [26]: np.round(dist, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "In [34]: import os  # for os.path.basename\n",
    "\n",
    "In [35]: import matplotlib.pyplot as plt\n",
    "\n",
    "In [36]: from sklearn.manifold import MDS\n",
    "\n",
    "# two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "In [37]: mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "In [38]: pos = mds.fit_transform(dist)  # shape (n_components, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "In [39]: xs, ys = pos[:, 0], pos[:, 1]\n",
    "In [40]: names = [os.path.basename(fn).replace('.txt', '') for fn in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二黄原板\n",
      "二黄慢板\n",
      "二黄摇板\n",
      "西皮原板\n",
      "西皮快板\n",
      "西皮慢板\n",
      "西皮摇板\n"
     ]
    }
   ],
   "source": [
    "for i in names:print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe4\\xba\\x8c\\xe9\\xbb\\x84\\xe5\\x8e\\x9f\\xe6\\x9d\\xbf',\n",
       " '\\xe4\\xba\\x8c\\xe9\\xbb\\x84\\xe6\\x85\\xa2\\xe6\\x9d\\xbf',\n",
       " '\\xe4\\xba\\x8c\\xe9\\xbb\\x84\\xe6\\x91\\x87\\xe6\\x9d\\xbf',\n",
       " '\\xe8\\xa5\\xbf\\xe7\\x9a\\xae\\xe5\\x8e\\x9f\\xe6\\x9d\\xbf',\n",
       " '\\xe8\\xa5\\xbf\\xe7\\x9a\\xae\\xe5\\xbf\\xab\\xe6\\x9d\\xbf',\n",
       " '\\xe8\\xa5\\xbf\\xe7\\x9a\\xae\\xe6\\x85\\xa2\\xe6\\x9d\\xbf',\n",
       " '\\xe8\\xa5\\xbf\\xe7\\x9a\\xae\\xe6\\x91\\x87\\xe6\\x9d\\xbf']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This plotting works out in the command line. see script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aaff910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "for x, y, name in zip(xs, ys, names):\n",
    "    \n",
    "    if '原板' in name:\n",
    "        color = 'orange'\n",
    "        print 'uyes'\n",
    "    elif '慢板' in name:\n",
    "        color = 'skyblue'\n",
    "    elif '摇板' in name:\n",
    "        color = 'red'\n",
    "    elif '快板' in name:\n",
    "        color = 'yellow'\n",
    "        \n",
    "    plt.scatter(x, y, c=color)\n",
    "    nameu=codecs.decode(name,'utf-8')\n",
    "    print name\n",
    "    plt.text(x, y, name) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(vocab_list)\n",
    "dtm.get_shape()\n",
    "#demo test\n",
    "print u'\\u4e0a' in vocab_list\n",
    "print codecs.decode('一些','utf-8') in vocab_list\n",
    "#vocab list has a number of vocabs of variable length, 1,2,3,4,...here are some len=1 words:\n",
    "for i in vocab_list[:1000]:\n",
    "    if len(i)==1:\n",
    "        print i,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing NMF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
